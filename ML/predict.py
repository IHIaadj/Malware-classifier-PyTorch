import numpy as np 
import torch 
import torch.nn as nn
import pkg_resources

class NeuralNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(NeuralNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size) 
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)  
    
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out
    

def predict(vector):
    resource_package = __name__
    resource_path = '/'.join(('', 'datasetFile.txt'))

    Xall_path = pkg_resources.resource_filename(resource_package, resource_path)
    dataset = np.loadtxt(fname=Xall_path, delimiter=',')
    X = dataset[:,0:-1]  # Omit last column 
    Y = dataset[:,-1]    # Get only last column 
  
    Y2 = Y.reshape(-1,1)
    X = X.reshape(-1,395)

    X1 = torch.tensor(X , dtype=torch.int)
    Y1 = torch.tensor(Y2 , dtype=torch.int)

    vector1 = torch.tensor(vector[:-1], dtype=torch.int)

    model = NeuralNet(395, 10, 1)
    
    '''
    ######################  Training part #########################"
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.03)  
    num_epochs = 2000

    for epoch in range(num_epochs):  # trains the NN 1,000 times
     
        outputs = model(X1.float())
        loss = criterion(outputs, Y1.float())
    
        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
       
        print ('Epoch [{}/{}], Loss: {:.4f}' 
            .format(epoch+1, num_epochs, loss.item()))

    torch.save(model.state_dict(), "checkpoint.pth")
    '''
    model.load_state_dict(torch.load("checkpoint.pth"))
    model.eval()
    output = model(vector1.float())
    if output > 0.5 : 
        prediction = 1
    else : 
        prediction = 0 
    print(prediction)
    return prediction